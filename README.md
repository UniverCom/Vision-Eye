üëÅÔ∏è Vision-Eye: AI-Driven Gaze & Voice Interface
()

An assistive technology solution bridging Eye-Tracking and Large Language Models (LLMs) to empower users with hands-free, multimodal interaction.

üèÜ Awards & Recognition
This project has been recognized for its innovative approach in AI and assistive technology:

ü•á 1st Place - Interuniversity AI Competition (Ba≈ükent University) | Dec 2024

Selected as the top project among 20+ teams from leading universities (ODT√ú, Bilkent, TOBB).

ü•à 2nd Place - Balkan AI Competition (FonPrime / Orscelik) | July 2024

üöÄ Overview
Vision-Eye is a novel human-computer interaction (HCI) system designed to eliminate physical input barriers. By combining high-precision Eye-Tracking with Generative AI, it allows users to navigate interfaces, select objects, and interact with complex systems solely using their gaze and voice.

The system acts as an intelligent orchestrator, understanding user intent through context-aware LLMs and executing commands in real-time.

Key Features
Multimodal Interaction: Seamless fusion of Gaze Tracking (Selection) and Voice (Command).

Context-Aware AI Core: Uses LLMs to understand the context of the user's screen and conversation.

Passive Listening & Triggering: Intelligent audio processing that detects user intent without constant wake-word repetition.

Dynamic UI Adaptation: Interface elements that respond to user attention.

üõ†Ô∏è Tech Stack & Architecture
Although the source code is private due to IP protection, the system is built upon a robust, modular architecture leveraging state-of-the-art open-source models:

Core Logic: Python (Orchestration & Signal Processing)

LLM & Intent Classification: Mistral-7B, Bert, RoBERTa (Fine-tuned for command extraction)

Speech Processing (STT/TTS): OpenAI Whisper (High-fidelity STT), ElevenLabs (Natural TTS)

Computer Vision: Custom Gaze Prediction Algorithms & OpenCV

Frontend/UI: PyQt / Kivy (for responsive eye-tracking interfaces)

Hardware Integration: Microphone Arrays & IR Eye-Tracking Sensors

‚ö†Ô∏è Project Status & License
Status: üîí Patent Pending / Proprietary

This repository serves as a technical showcase and research overview of the Vision-Eye project.

Due to ongoing patent applications and commercialization processes, the source code and detailed architectural diagrams are currently classified and not open for public use. The technical implementation details involving the synchronization of the Gaze-Prediction Module with the LLM Context Hub remain proprietary.

For detailed technical inquiries, partnership opportunities, or to request a private demo of the architecture, please contact me directly.

üì¨ Contact
Erdeniz √á√∂kren AI Engineer & Researcher

LinkedIn: linkedin.com/in/erdeniz-√ß√∂kren

Email: erdeniz.cokren@outlook.com

¬© 2024 Vision-Eye Project. All Rights Reserved.
