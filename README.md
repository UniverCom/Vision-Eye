**üëÅÔ∏è Vision-Eye: AI-Driven Gaze & Voice Interface**
![Vision-Eye Concept](vision-eye-cover.png)

An assistive technology solution bridging Eye-Tracking and Large Language Models (LLMs) to empower users with hands-free, multimodal interaction.

üèÜ Awards & Recognition
This project has been recognized for its innovative approach in AI and assistive technology:

ü•á 1st Place - Interuniversity AI Competition (Ba≈ükent University) | Dec 2024

Selected as the top project among 20+ teams from leading universities (ODT√ú, Bilkent, TOBB).

ü•à 2nd Place - Orscelik Balkan AI Competition 2024 (FonPrime) | July 2024

**Overview**

Vision-Eye is a novel human-computer interaction (HCI) system designed to eliminate physical input barriers. By combining high-precision Eye-Tracking with Generative AI, it allows users to navigate interfaces, select objects, and interact with complex systems solely using their gaze and voice.

The system acts as an intelligent orchestrator, understanding user intent through context-aware LLMs and executing commands in real-time.

**Key Features**
Multimodal Interaction: Seamless fusion of Gaze Tracking (Selection) and Voice (Command).

Context-Aware AI Core: Understands the context of the user's screen and conversation.

Passive Listening & Triggering: Intelligent audio processing that detects user intent without constant wake-word repetition.

Dynamic UI Adaptation: Interface elements that respond to user attention.

This repository serves as a conceptual showcase and research overview of the Vision-Eye project.

Due to ongoing patent applications and commercialization processes, the source code and detailed architectural diagrams are currently classified and not open for public use. The technical implementation details remain proprietary.


**Erdeniz Cokren AI Engineer & Researcher**

¬© 2025 Vision-Eye Project. All Rights Reserved.
